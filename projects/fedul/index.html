<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A Bi-Objective Optimization Approach for Enhancing FedUL | Abdullah Ahmed Alzahrani </title> <meta name="author" content="Abdullah Ahmed Alzahrani"> <meta name="description" content="Algorithm Analysis"> <meta name="keywords" content="Abdullah-Alzahrani, Abdullah-Ahmed-Alzahrani, ML-Engineer, AI-Engineer, Electrical-Engineer"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://abodeza.github.io/projects/fedul/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Abdullah</span> Ahmed Alzahrani </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/certificates/">awards &amp; certificates </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">A Bi-Objective Optimization Approach for Enhancing FedUL</h1> <p class="post-description">Algorithm Analysis</p> </header> <article> <p>Formal report can be found here: <a href="/assets/pdf/ECSE_4964_Project_Report.pdf">pdf</a>.</p> <hr> <div id="toc"> <h2>Table of Contents</h2> <ul> <li><a href="#introduction">Introduction</a></li> <li><a href="#our-contribution">Our Contribution</a></li> <li><a href="#proposed-algorithm">Proposed Algorithm</a></li> <li><a href="#empirical-results">Empirical Results</a></li> <li><a href="#conclusion-and-future-work"> Conclusion and Future Work</a></li> <li><a href="#references"> References</a></li> <li><a href="#appendix"> Appendix</a></li> </ul> </div> <hr> <h1 id="introduction">Introduction</h1> <p>In this project, we aim to minimize the cost function associated with multi-class classification tasks. Training local models in unsupervised federated learning settings using decentralized datasets can encounter numerous obstacles. These include the absence of a definitive objective function for model evaluation. Unlike unsupervised learning, where generative models like GANs or diffusion models excel at modeling data distributions, federated learning contends with heterogeneous datasets. This heterogeneity can prevent local models from acquiring generalizable knowledge and complicate the aggregation of these models on the server side.</p> <h2 id="related-work">Related Work</h2> <h4 id="fedul">FedUL</h4> <p>is an algorithm designed to overcome the challenge of unclear objectives in the unsupervised FL setting. It begins with the natural segregation of data across clients, splitting each client‚Äôs dataset into multiple subsets. Each subset is indexed relative to the client‚Äôs dataset, serving as the surrogate label. This approach facilitates training on surrogate data using a supervised task. Thus, the objective becomes minimizing the loss function associated with predicting the surrogate labels. The algorithm assumes we have access to the class priors and a shared class-conditional distribution among clients. The primary goal of FedUL is to use an injective transition function <span class="math inline"><em>Q</em></span> to recover the optimal model from the surrogate task, ensuring that the knowledge acquired is applicable for classifying the actual data.</p> <p>This goal is achieved by implementing Theorem 1 from the paper, which establishes a method to correlate the posterior probabilities of the real and surrogate data. Specifically, it assesses the likelihood of each surragate dataset chosen per client. Which is approximated as the number of features for that dataset over the total number of features for the client. Then it maps posterior probability from the real space to the space of the surrogate data. Then it utilizes the prior probability of the real classes to assess the likelihood of a class‚Äôs presence in a client‚Äôs dataset, effectively normalizing the posterior probability predicted by the global model, which is the last matrix in the unnormalized representation of the injective function. By optimizing the surrogate classifier, the classifier for the actual task is concurrently enhanced, supported by other assumptions detailed in the paper.</p> <h2 class="unnumbered" id="theorem-1">Theorem 1</h2> <p>For each client <span class="math inline"><em>c</em>‚ÄÑ‚àà‚ÄÑ[<em>C</em>]</span>, let <span class="math inline"><em>Œ∑ÃÑ</em><sub><em>c</em></sub>‚ÄÑ:‚ÄÑùí≥‚ÄÑ‚Üí‚ÄÑ<em>Œî</em><sup><em>M</em>‚ÄÖ‚àí‚ÄÖ1</sup></span> and <span class="math inline"><em>Œ∑</em>‚ÄÑ:‚ÄÑùí≥‚ÄÑ‚Üí‚ÄÑ<em>Œî</em><sup><em>K</em>‚ÄÖ‚àí‚ÄÖ1</sup></span> be the surrogate and original class-posterior probability functions, respectively, where <span class="math inline">(<em>Œ∑ÃÑ</em><sub><em>c</em></sub>(<em>x</em>))<sub><em>m</em></sub>‚ÄÑ=‚ÄÑ<em>pÃÑ</em><sub><em>c</em></sub>(<em>yÃÑ</em>‚ÄÑ=‚ÄÑ<em>m</em>‚ÄÖ‚à£‚ÄÖ<em>x</em>)</span> for <span class="math inline"><em>m</em>‚ÄÑ‚àà‚ÄÑ[<em>M</em>]</span>, and <span class="math inline">(<em>Œ∑</em>(<em>x</em>))<sub><em>k</em></sub>‚ÄÑ=‚ÄÑ<em>p</em>(<em>y</em>‚ÄÑ=‚ÄÑ<em>k</em>‚ÄÖ‚à£‚ÄÖ<em>x</em>)</span> for <span class="math inline"><em>k</em>‚ÄÑ‚àà‚ÄÑ[<em>K</em>]</span>. Here, <span class="math inline"><em>Œî</em><sup><em>M</em>‚ÄÖ‚àí‚ÄÖ1</sup></span> and <span class="math inline"><em>Œî</em><sup><em>K</em>‚ÄÖ‚àí‚ÄÖ1</sup></span> are the <span class="math inline"><em>M</em></span>-dimensional and <span class="math inline"><em>K</em></span>-dimensional simplexes, respectively.</p> <p>Let <span class="math inline"><em>œÄÃÑ</em><sub><em>c</em></sub>‚ÄÑ=‚ÄÑ[<em>œÄÃÑ</em><sub>1<em>c</em></sub>,‚ÄÜ‚Ä¶,‚ÄÜ<em>œÄÃÑ</em><sub><em>M</em><em>c</em></sub>]<sup>‚ä§</sup></span> and <span class="math inline"><em>œÄ</em>‚ÄÑ=‚ÄÑ[<em>œÄ</em><sub>1</sub>,‚ÄÜ‚Ä¶,‚ÄÜ<em>œÄ</em><sub><em>K</em></sub>]<sup>‚ä§</sup></span> be vector forms of the surrogate and original class priors, respectively. Let <span class="math inline"><em>Œ†</em><sub><em>c</em></sub>‚ÄÑ‚àà‚ÄÑ‚Ñù<sup><em>M</em>‚ÄÖ√ó‚ÄÖ<em>K</em></sup></span> be the matrix form of <span class="math inline"><em>œÄ</em><sub><em>m</em>,‚ÄÜ<em>k</em></sub><sup><em>c</em></sup>‚ÄÑ=‚ÄÑ<em>p</em><sub><em>m</em></sub><sup><em>c</em></sup>(<em>y</em>‚ÄÑ=‚ÄÑ<em>k</em>)</span> . Then we have: <span class="math display">$$\bar{\eta}_c(x) = Q_c(\eta(x); \pi, \bar{\pi_c}, \Pi_c)$$</span> where the unnormalized version of the vector-valued function <span class="math inline"><em>Q</em><sub><em>c</em></sub></span> is given by: <span class="math display"><em>QÃÉ</em><sub><em>c</em></sub>(<em>Œ∑</em>(<em>x</em>);‚ÄÜ<em>œÄ</em>,‚ÄÜ<em>œÄÃÑ</em><sub><em>c</em></sub>,‚ÄÜ<em>Œ†</em><sub><em>c</em></sub>)‚ÄÑ=‚ÄÑ<em>D</em><sub><em>œÄÃÑ</em><sub><em>c</em></sub></sub>‚ÄÖ‚ãÖ‚ÄÖ<em>Œ†</em><sub><em>c</em></sub>‚ÄÖ‚ãÖ‚ÄÖ<em>D</em><sub><em>œÄ</em></sub><sup>‚àí1</sup>‚ÄÖ‚ãÖ‚ÄÖ<em>Œ∑</em>(<em>x</em>).</span> Here, <span class="math inline"><em>D</em><sub><em>a</em></sub></span> denotes the diagonal matrix with the diagonal terms being vector <span class="math inline"><em>a</em></span>, and ‚Äò<span class="math inline">‚ãÖ</span>‚Äô denotes matrix multiplication. <span class="math inline"><em>Q</em><sub><em>c</em></sub></span> is normalized by the sum of all entries, i.e., <span class="math inline">$(Q_c)_i = \frac{(\tilde{Q}_{ec})_i}{\sum_j (Q_{c})_j}$</span>.</p> <h1 id="our-contribution">Our Contribution</h1> <h2 id="overview">Overview</h2> <p>We introduce an enhanced algorithm designed to enhance the performance of FedUL in terms of accuracy and robustness. Recognizing FedUL‚Äôs effectiveness, our approach integrates FedUL with an additional optimization phase utilizing supervised learning techniques. This integration involves training local models using FedUL, aggregating these models at the server, and subsequently implementing a bi-objective optimization task trained on publicly accessible labeled data, aiming for Pareto optimality. This approach has shown to improve FedUL‚Äôs performance, especially in non-IID settings.</p> <h2 id="significance">Significance</h2> <p>Despite the scarcity of publicly accessible labeled datasets in many areas, our method leverages any applicable available small-sized labeled dataset in conjunction with a larger decentralized dataset. This approach preserves the privacy of client data while enhancing the model‚Äôs performance through bi-objective optimization techniques.</p> <h2 id="integration-techniques">Integration Techniques</h2> <p>To integrate the updates from local models with the supervised model‚Äôs updates, we explored two methods:</p> <h3 id="method-1-feedback-optimization">Method 1: Feedback Optimization</h3> <p>In this approach, we fine-tune the aggregated global model using the labeled data retained at the server. This phase optimizes the objective of the server‚Äôs model based on the labeled data. Following this, we establish a feedback loop by redistributing the fine-tuned model back to the clients. This loop allows the clients to further optimize the model with their local data, enhancing the overall accuracy of the model.</p> <h3 id="method-2-independent-enhancement">Method 2: Independent Enhancement</h3> <p>Alternatively, we execute the FedUL process to aggregate the local models into a global model. Parallel to this, we optimize an independent model, intialized uniformly with the global model, specifically on the labeled data. The parameters learned from this supervised task are then combined with the global model‚Äôs parameters. This combination is regulated through a manually tuned hyper-parameter, effectively blending the insights of both the local models and the supervised model. A similar loop to method 1 is implemented.</p> <h2 id="proposed-algorithm">Proposed Algorithm</h2> <div class="algorithm-block"> <strong>Algorithm 1:</strong> Federation of unsupervised learning (FedUL)<br> <b>Server Input:</b> initial \( f \), global step-size \( \alpha_g \), and global communication round \( R \)<br> <b>Client \( c \)‚Äôs Input:</b> local model \( f_c \), unlabeled training sets \( U_c = \{U_{c}^m\}_{m=1}^{M_c} \), class priors \( \Pi_c \) and \( \pi \), local step-size \( \alpha_l \), and local updating iterations \( L \) <ol> <li>Start with initializing clients with Procedure A.</li> <li>For \( r = 1 \to R \): <ul> <li>Run Procedure B and Procedure C iteratively.</li> </ul> </li> <li> <b>Procedure A. ClientInit(c):</b> <ul> <li>Transform \( U_c \) to a surrogate labeled dataset \( U_c \) according to (6)</li> <li>Modify \( f \) to \( g_c = Q_c(f) \), where \( Q_c \) is computed according to Theorem 1</li> </ul> </li> <li> <b>Procedure B. ClientUpdate(c):</b> <ul> <li>\( f_c \leftarrow f \) ¬† <i>// Receive updated model from ServerExecute</i> </li> <li>\( g_c \leftarrow Q_c(f_c) \)</li> <li>For \( l = 1 \to L \): <ul> <li>\( g_c \leftarrow g_c - \alpha_l \nabla J_b(g_c; U_c) \) ¬† <i>// SGD update based on (7)</i> </li> <li>\( f_c \leftarrow f_c - \alpha_l \nabla J_b(Q_c(f_c); U_c) \) ¬† <i>// Update on \( g_c \) induces update on \( f_c \)</i> </li> </ul> </li> <li>Send \( f_c - f \) to ServerExecute</li> </ul> </li> <li> <b>Procedure C. ServerExecute(r):</b> <ul> <li>If using Method 1: <ul> <li>Fine-tune \( f \) on the server‚Äôs labeled data</li> </ul> </li> <li>Else if using Method 2: <ul> <li>Independently train a model \( f' \) on labeled data</li> <li>\( f \leftarrow (1 - \text{hyperparameter}) \times f + \text{hyperparameter} \times f' \)</li> <li>Broadcast updated \( f \) to ClientUpdate</li> </ul> </li> </ul> </li> </ol> </div> <h1 id="empirical-results">Empirical Results</h1> <h2 id="experimental-setup">Experimental setup</h2> <p>The experiments were done on the MNIST dataset using a CNN with the exact dimensions and parameters as conducted in the experiments of FedUL, with exception of a batch size of 100 instead of 128 for splitting considerations. The goal is achieve a performance better than that of FedUL‚Äôs and validate the approach of bi-objective optimization. Below is a table comparing our model‚Äôs mean error compared to FedUL‚Äôs, with FedUL+M<span class="math inline"><em>x</em></span> being a place holder for our algorithm with method <span class="math inline">#<em>x</em></span>. The best performing model on the validation data is chosen.</p> <div id="sample-table"> <table> <caption>Setup</caption> <thead> <tr> <th colspan="2" style="text-align: center;"></th> <th style="text-align: left;"></th> </tr> </thead> <tbody> <tr> <td style="text-align: left;"> <span>1-3</span> Clients</td> <td style="text-align: left;">Parameters</td> <td style="text-align: left;">Data Splitting</td> </tr> <tr> <td style="text-align: left;"> <span class="math inline">#</span>C = 5</td> <td style="text-align: left;"><span class="math inline"><em>Œ±</em>‚ÄÑ=‚ÄÑ1<em>e</em>‚ÄÖ‚àí‚ÄÖ4</span></td> <td style="text-align: left;">Test: 10k</td> </tr> <tr> <td style="text-align: left;">Set/C = 10</td> <td style="text-align: left;">batch = 100</td> <td style="text-align: left;">FedUL: 36k</td> </tr> <tr> <td style="text-align: left;"></td> <td style="text-align: left;">epochs = 100</td> <td style="text-align: left;">Supervised task: 12k</td> </tr> <tr> <td style="text-align: left;"></td> <td style="text-align: left;">method 2‚Äôs hyperparameter: 0.5</td> <td style="text-align: left;">Validation: 12k</td> </tr> </tbody> </table> </div> <h2 id="results">Results</h2> <div id="sample-table"> <table> <caption>Mean Error Rates</caption> <thead> <tr> <th colspan="2" style="text-align: center;"></th> <th style="text-align: left;"></th> </tr> </thead> <tbody> <tr> <td style="text-align: left;"> <span>1-3</span> Algorithm</td> <td style="text-align: left;">Mean Error (IID)</td> <td style="text-align: left;">Mean Error (non-IID)</td> </tr> <tr> <td style="text-align: left;">FedUL</td> <td style="text-align: left;">0.78</td> <td style="text-align: left;">2.98</td> </tr> <tr> <td style="text-align: left;">FedUL+M1</td> <td style="text-align: left;">0.69</td> <td style="text-align: left;">0.77</td> </tr> <tr> <td style="text-align: left;">FedUL+M2</td> <td style="text-align: left;">0.69</td> <td style="text-align: left;">0.79</td> </tr> </tbody> </table> </div> <h2 class="unnumbered" id="note">Note</h2> <p>Additionally, plots showing the mean error and losses per epoch are included and briefly discussed in the appendix.</p> <h1 id="conclusion-and-future-work">Conclusion and Future Work</h1> <p>In conclusion, we found that implementing a bi-objective optimization with FedUL and a supervised model can significantly enhance the performance of a standalone FedUL model, particularly when applied to non-IID datasets. Our research has demonstrated two key findings. First, FedUL is capable of learning concurrently with a supervised federated learning technique without the objectives interfering destructively with each other. Second, the integration of knowledge from a supervised model into FedUL not only boosts its accuracy but also facilitates faster convergence. In the current setting, method 1 seems to be perform better than method 2.<br> </p> <p>Looking ahead, future work could focus on several areas. Extensive validation of the algorithm under diverse settings and with various models could further establish its robustness and adaptability. Additionally, optimizing the hyperparameter tuning process to enhance performance and ease of use. Finally, examining the impacts of different data distributions and more extreme cases of non-IID data could provide deeper understanding for broader applications in real-world scenarios.</p> <h1 class="unnumbered" id="references">References</h1> <p>[1] Lu, N., Wang, Z., Li, X., Niu, G., Dou, Q., &amp; Sugiyama, M. (2022) Federated Learning from Only Unlabeled Data with Class-Conditional-Sharing Clients. In <em>International Conference on Learning Representations</em>. Available: <a href="https://openreview.net/forum?id=WHA8009laxu" class="uri" rel="external nofollow noopener" target="_blank">https://openreview.net/forum?id=WHA8009laxu</a></p> <p><strong>Code:</strong> The code used to provide the empirical results is a heavily modified version of the code the authors Lu, N et. al. used and can be found here, under federated. choose fedulmnist.py:</p> <div class="center"> <p><a href="https://rpi.box.com/s/y86pvaxxs5sn2sj6huwhrvs2xahszmi6" class="uri" rel="external nofollow noopener" target="_blank">https://rpi.box.com/s/y86pvaxxs5sn2sj6huwhrvs2xahszmi6</a></p> </div> <p><strong>Instructions:</strong> This is the link for the GitHub repository of FedUL algorithm, which mostly covers how to run the code. For extra information please contact me:</p> <div class="center"> <p><a href="https://github.com/lunanbit/FedUL?tab=readme-ov-file" class="uri" rel="external nofollow noopener" target="_blank">https://github.com/lunanbit/FedUL?tab=readme-ov-file</a></p> </div> <h1 class="unnumbered" id="appendix">Appendix</h1> <h2 class="unnumbered" id="discussion">Discussion</h2> <h3 id="loss">Loss</h3> <p>Shown in Figure 1 is the supervised learning loss and surrogate task loss when performing the hybrid model, compared to the loss of performing standalone FedUL. The loss of the surrogate task and FedUL seems to be exact, with the exception that the surrogate task‚Äôs drops faster initially. This shows the positive influence of the hybrid model on adjusting the parameters of the clients‚Äô end. Additionally, the loss of all models seem to consistently decrease, indicating a shared objective.</p> <p>It is also worth mentioning that Figures 2 and 4 show the loss dropping much faster than the Figures 1 and 3. This indicates that method 2 can lead to faster convergence.</p> <h3 id="error-rate">Error Rate</h3> <p>In figure 5, we see a clearer picture of how the hybrid model outperforms the Standalone FedUL Algorithm. It consistently has lower error rates and converges faster. Additionally, in figures 7 and 8, the mean error shows a steep decrease which indicates that the hybrid model handles the non-IID datasets well.</p> <h2 id="supplementing-figures">Supplementing Figures</h2> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Learning%20Loss%20and%20Surrogate%20loss%20Method%201%20(IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 1: Learning Loss and Surrogate loss Method 1 (IID). </div> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Learning%20Loss%20and%20Surrogate%20loss%20Method%202%20(IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 2: Learning Loss and Surrogate loss Method 2 (IID). </div> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Learning%20Loss%20and%20Surrogate%20loss%20Method%201%20(non-IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 3: Learning Loss and Surrogate loss Method 1 (non-IID). </div> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Learning%20Loss%20and%20Surrogate%20loss%20Method%202%20(non-IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 4: Learning Loss and Surrogate loss Method 2 (non-IID). </div> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Mean%20Error%20Rate%20Method%201%20(IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 5: Mean Error Rate Method 1 (IID). </div> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Mean%20Error%20Rate%20Method%202%20(IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 6: Mean Error Rate Method 2 (IID). </div> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Mean%20Error%20Rate%20Method%201%20(non-IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 7: Mean Error Rate Method 1 (non-IID). </div> <div style="display: flex; justify-content: center; margin-bottom: 1.5em;"> <img src="/assets/img/fedul/Mean%20Error%20Rate%20Method%202%20(non-IID).png" alt="Confusion Matrix for Classification Model Testing" style="width: 600px; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.15);"> </div> <div class="caption"> Figure 8: Mean Error Rate Method 2 (non-IID). </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Abdullah Ahmed Alzahrani. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. This site uses Google Analytics to measure anonymous engagement. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-CZKWWGTH6B"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-CZKWWGTH6B');
  </script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>